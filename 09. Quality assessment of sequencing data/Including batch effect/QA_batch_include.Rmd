---
title: "Qualtiy Assessment of sequencing data"
subtitle: "Including batch information"
author: "Yura SONG"
output: html_notebook
---

# Introduction

Here, we will do quality assessment, which is mandatory before starting analysis. With quality assessment, we could get further information about a set of samples: outlier, clustering or library size.

The dataset is generated from two different timepoint (D13 and Adult) and two different tissue origins (called A and B). Also, the sequencing has been done in two different timepoint. 

# Preparation

Before starting the analysis on the RNA-seq data, the first thing to do is attaching libraries which we need further.
```{r attach library}
library(DESeq2)
library(pheatmap)
library(RColorBrewer)
```

## Data preparation

For starting analysis, we will import raw-count data. Raw-count table includes the counts of reads in each transcript, counted by HTseq-count. The genes whether counts is zero on all samples or the mitochondreal genes, they were filtered out.
```{r import raw count}
count <- read.delim("data/rawcount.csv", h=T, sep=",")
head(count)
```

It seems that the data is successfully imported. 

The quality assessment will be based on the DESeq2, therefore, we should generate the matrices which will be used for generating DESeq2 object. One matrix will include raw-count of gene expression and another will composed of the sample information. 

```{r making countData}
countData <- count[,2:ncol(count)]
rownames(countData) <- count[,1]
```

For sample information, the condition of sample, precise name of samples, and batch effect are required. For batch information, *rep()* could be used, rather than putting same information for several times.
```{r making colData}
colData <- data.frame(condition=c("D13A", "D13A", "D13A", "D13B", "D13B", "D13B", "AdultA", "AdultA", "AdultB", "AdultB"),
                      precise=c("D13_A1", "D13_A2","D13_A3","D13_B1", "D13_B2","D13_B3","Adult_D1", "Adult_D2","Adult_B1","Adult_B2"),
                      batch=c("1", "1", "2", "1", "1", "2", rep("1", 4)))
rownames(colData) <- colnames(countData)
head(colData)
```

##DESeq2 object

To build a DESeq Data Set object, we need to provide 3 elements: 1. A matrix of raw read counts for all genes in all samples, countData in our case. 2. A dataframe providing information about all samples, colData in our case. 3. A design, which we would like to compare each other. It’s simply the condition of sample. We use condition because it corresponds to the column name in colData.

We will build DESeq2 object, for calculating the size factor. Also, not like previously, **both batch and condition** should be considered.

```{r DESeq2 object}
dds <- DESeqDataSetFromMatrix(countData, colData, design = ~batch + condition)
```

While the pre-filteration of low count before running DESeq2 is not mandatory, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and we increase the speed of the transformation and testing functions within DESeq2. Here we perform a minimal pre-filtering to keep only rows if there is at least one gene has expression. Note that more strict filtering to increase power is automatically applied via independent filtering on the mean of normalized counts within the results function.
```{r filtration}
keep <- rowSums(counts(dds)) > 0
dds <- dds[keep,]
```

# Pre-process

## Normalization
We will do data normalization as a first step of data normalization. The first parameter that influences gene read counts is the sequencing depth, the gene will get more or less reads depending on how much the samples were sequenced. For this reason, we need to do normalize the data for sequencing depth.

In DESeq2, with estimateSizeFactors function that uses the median ratio method.Ssize factor for each sample would be calculated and it corresponds to the multiplication factor which could be used to normalize the counts for sample sequencing depth.
```{r size factor calculation}
dds <- estimateSizeFactors(dds)
sizeFactors(dds)
```

The size factors are calculated! For the normalization, we will see the read count distribution before normalization and after normalization on DESeq2. Let’s have a look.
```{r before normalization}
boxplot(log2(1 + counts(dds, normalized = FALSE) ), las=3, cex.axis=0.8, ylab="log2(1+counts)", main="Before normalization")
```

```{r after normalization}
boxplot(log2(1 + counts(dds, normalized = TRUE) ), las=3, cex.axis=0.8, ylab="log2(1+counts)", main="After normalization")
```

DESeq2 performs an internal normalization where geometric mean is calculated for each gene across all samples. The counts for a gene in each sample is then divided by this mean. The median of these ratios in a sample is the size factor for that sample. This procedure corrects for library size and RNA composition bias, which can arise for example when only a small number of genes are very highly expressed in one experiment condition but not in the other. 

##Data transformation

Transformations are also important for variance stabilization. When we want to compare samples or perform statistical test, we need to make sure that the signal is not dominated by a certain class of genes, for instance, the peaks whose peak intensity is too high or too low. Indeed, for highly expressed genes, a few percent of variation in expression will translate into large differences in absolute number of reads.

In our case, the regularized log transformation of the gene counts for all samples is performed using the rlog function on the DESeq2 Data Set object.

```{r reg-log transformation}
rld <- rlog(dds)
```

#Quality accessment

##Expression values on replicates

As a first step of quality accessment, we could compare the the counts for two biological replicates to see the impact of the transformations. Here, what we could expect is that the correlation between two replicates will strong positive and linear correlation.
```{r replicate - D13A}
par(mfrow=c(2,3))
plot( counts(dds, normalized = TRUE)[,1:2], pch=16, cex=0.5, main = "No transf-D13A1 vs D13A2")
abline(0, 1, lty=4, col="red")
plot( counts(dds, normalized = TRUE)[,1:3], pch=16, cex=0.5, main = "No transf-D13A1 vs D13A3")
abline(0, 1, lty=4, col="red")
plot( counts(dds, normalized = TRUE)[,2:3], pch=16, cex=0.5, main = "No transf-D13A2 vs D13A3")
abline(0, 1, lty=4, col="red")

plot( assay(rld)[,1:2], pch=16, cex=0.5, main="Reg-log-D13A1 vs D13A2", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
plot( assay(rld)[,1:3], pch=16, cex=0.5, main = "Reg-log-D13A1 vs D13A3", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
plot( assay(rld)[,2:3], pch=16, cex=0.5, main = "Reg-log-D13A2 vs D13A3", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
```

```{r replicate - D13B}
par(mfrow=c(2,3))
plot( counts(dds, normalized = TRUE)[,4:5], pch=16, cex=0.5, main = "No transf-D13B1 vs D13B2")
abline(0, 1, lty=4, col="red")
plot( counts(dds, normalized = TRUE)[,4:6], pch=16, cex=0.5, main = "No transf-D13B1 vs D13B3")
abline(0, 1, lty=4, col="red")
plot( counts(dds, normalized = TRUE)[,5:6], pch=16, cex=0.5, main = "No transf-D13B2 vs D13B3")
abline(0, 1, lty=4, col="red")

plot( assay(rld)[,4:5], pch=16, cex=0.5, main="Reg-log-D13B1 vs D13B2", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
plot( assay(rld)[,4:6], pch=16, cex=0.5, main = "Reg-log-D13B1 vs D13B3", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
plot( assay(rld)[,5:6], pch=16, cex=0.5, main = "Reg-log-D13B2 vs D13B3", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
```

```{r replicate - Adult}
par(mfrow=c(2,2))
plot( counts(dds, normalized = TRUE)[,7:8], pch=16, cex=0.5, main = "No transformation-Adult A")
abline(0, 1, lty=4, col="red")
plot( counts(dds, normalized = TRUE)[,9:10], pch=16, cex=0.5, main = "No transformation-Adult B")
abline(0, 1, lty=4, col="red")

plot( assay(rld)[,7:8], pch=16, cex=0.5, main="Reg-log-Adult A", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
plot( assay(rld)[,9:10], pch=16, cex=0.5, main="Reg-log-Adult B", xlim=c(0,20), ylim=c(0,20))
abline(0, 1, lty=4, col="red")
```

Here, what we could know are as below
  - D13A2 and D13A3 : not so strong correlation between each other
  - D13B2 vs D13B3 : not so strong correlation between each other

Still the correlation in adult replicates are okay. However, this correlation information is not enough. 

##Clustering and Principal Component Analysis

###Clustering based on the euclidean distance

We will show two classical approaches to sample comparison. - Clustering based on euclidean distances between samples - Principal Component Analysis

First one is **Euclidean distance** between samples. The Euclidean distance is straight-line distance between two points in an Euclidean space. It could be simply understood, just distance between the two point! Similarly, we can calculate distances for all possible pairs of samples. However, we will use the multi-dimentional space with as many dimensions as the number of genes we want to take into account for that calculation.

In the present case, we will simply use all genes for which we have counts. We’ll make sure to use normalized and rlog transformed data so that the distance doesn’t simply reflect sequencing depth and is not dominated by a subset of genes.
```{r euclidean distance}
sampleDists <- dist( t( assay(rld) ) )
```

Then we will generate heatmaps for this euclidean distance between samples to visualize the distance, how much samples are far or near. For heatmap, **normalized regularized-log-transformed** data was used.
```{r plotting cluster}
sampleDistMatrix <- as.matrix( sampleDists ) 
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255) 
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors,
         annotation_col =colData[,c(1,3)]
         )
```

###Correlation plot

Also, we could check the correlation between replicates by calculating **Pearson correlation coefficient**. They could be reported as heatmap with clustering, as similar way of previous plot.
```{r correlation plot}
# calculate correlation between pairs of samples for all possible pairs.
sampleCor <- cor(assay(rld))
# generate heatmap
pheatmap(
  as.matrix(sampleCor),
  annotation_col =as.data.frame(colData(rld)[,c(1,3)]),
  main = "Correlation clustering",
  width = 12,
  height = 10
)
```

From the unsupervised clustering and correlation plot, it seems that the batch effect is clear.

###PCA plot
Next one is **Principal Component Analysis**, as known as PCA. Principal Component Analysis is a classical dimensionality reduction method. The point is to reduce the number of dimensions to something manageable while loosing a minimal amount of information.

For visualization, the other packages need to be attached.
```{r attach additional libraries}
library(factoextra)
library(ggfortify)
library(ggrepel)
```

Since the data is already transformed, the scaling is not required. Let’s check how many dimensions are explaining the variances.
```{r dimention for variances}
pca <- prcomp(t(assay(rld)), center=TRUE, scale.=FALSE)
fviz_eig(pca)
```

So there are total 10 explained variances and mostly are explained by PC1 and PC2. To reduce the dimensions which explains the variance, let’s check the data by PCA plot.

```{r pca plot}
plotPCA(rld, intgroup="condition") + geom_text_repel(aes(label = colData(rld)$precise))
```

```{r pca plot batch}
plotPCA(rld, intgroup="batch") + geom_text_repel(aes(label = colData(rld)$precise))
```

Okay, from the PCA plot, again we could check the batch effect. To see the effect from different condition, we should check the data after removing batch effect.

##Batch effect removed

To exclude the effect from batch information, we could use *removeBatchEffect* function from limma package. 
```{r batch effect correction}
vsd <- vst(dds, blind=FALSE)

mat <- assay(vsd)
mat <- limma::removeBatchEffect(mat, vsd$batch)
assay(vsd) <- mat
plotPCA(vsd) + geom_text_repel(aes(label = colData(rld)$precise)) + ggtitle("Sample PCA, regularized-log-transformed normalized data")
```

### Quality accessment after batch effect correction

On the PCA plot, it seems that the batch effect correction works, although not perfectly. Since the PCA plot is one of the method to see the variances by dimention reduction, we need to check the correlation and clustering as we did before batch effect correction.

```{r euclidean distance vsd}
sampleDists_vsd <- dist( t( assay(vsd) ) )
```

```{r plotting cluster vsd}
sampleDistMatrix <- as.matrix( sampleDists_vsd ) 
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255) 
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists_vsd,
         clustering_distance_cols=sampleDists_vsd,
         col=colors,
         annotation_col =colData[,c(1,3)]
         )
```

```{r correlation plot vsd}
# calculate correlation between pairs of samples for all possible pairs.
sampleCor <- cor(assay(vsd))
# generate heatmap
pheatmap(
  as.matrix(sampleCor),
  annotation_col =as.data.frame(colData(vsd)[,c(1,3)]),
  main = "Correlation clustering",
  width = 12,
  height = 10
)
```

Now we got quality assessment plots after excluding batch effect. Now, we could merge all the information to decide what to be filtered out.

# Conclusion

To check the linear correlation between replicates, D13A2 and D13A3, D13B2 vs D13B3 sets did not show strong correlation. Also, when checking the unsupervised clustering results and correlation clusteirng, D13B2 and D13A3 were clustered with other different conditions. 

When checking the PCA plots, still both D13B2 and D13A3 were far from the expectation, with showing higher variance. Therefore, for quality control, D13B2 and D13A3 would be excluded of further analysis.

```{r}
save.image("QA_batch_include.RData")
```




















